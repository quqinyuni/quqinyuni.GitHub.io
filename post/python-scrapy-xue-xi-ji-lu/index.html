<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" >

<title>python-scrapy学习记录 | test</title>

<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1, user-scalable=no">

<link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.7.2/css/all.css" integrity="sha384-fnmOCqbTlWIlj8LyTjo7mOUStjsKC4pOpQbqyi7RrhN7udi9RwhKkMHpvLbHG9Sr" crossorigin="anonymous">
<link rel="shortcut icon" href="https://quqinyuni.github.io//favicon.ico?v=1599121101701">
<link rel="stylesheet" href="https://quqinyuni.github.io//styles/main.css">



<link rel="stylesheet" href="https://unpkg.com/aos@next/dist/aos.css" />
<script src="https://cdn.jsdelivr.net/npm/vue/dist/vue.js"></script>



    <meta name="description" content="scrapy 是 python 的一个爬虫框架，便于快速建立一个爬虫项目。
scrapy 的安装及配置网上教程一大把，在此不做赘述，此文的主要目的是记录所遇到的坑。

字 数：437,阅读时间:1m 46s
1、爬虫速度
​	关于这个，se..." />
    <meta name="keywords" content="python" />
  </head>
  <body>
    <div id="app" class="main">

      <div class="sidebar" :class="{ 'full-height': menuVisible }">
  <div class="top-container" data-aos="fade-right">
    <div class="top-header-container">
      <a class="site-title-container" href="https://quqinyuni.github.io/">
        <img src="https://quqinyuni.github.io//images/avatar.png?v=1599121101701" class="site-logo">
        <h1 class="site-title">test</h1>
      </a>
      <div class="menu-btn" @click="menuVisible = !menuVisible">
        <div class="line"></div>
      </div>
    </div>
    <div>
      
        
          <a href="/" class="site-nav">
            首页
          </a>
        
      
        
          <a href="/archives" class="site-nav">
            归档
          </a>
        
      
        
          <a href="/tags" class="site-nav">
            标签
          </a>
        
      
        
          <a href="/post/about" class="site-nav">
            关于
          </a>
        
      
    </div>
  </div>
  <div class="bottom-container" data-aos="flip-up" data-aos-offset="0">
    <div class="social-container">
      
        
      
        
      
        
      
        
      
        
      
    </div>
    <div class="site-description">
      温故而知新
    </div>
    <div class="site-footer">
      Powered by <a href="https://github.com/getgridea/gridea" target="_blank">Gridea</a> | <a class="rss" href="https://quqinyuni.github.io//atom.xml" target="_blank">RSS</a>
    </div>
  </div>
</div>


      <div class="main-container">
        <div class="content-container" data-aos="fade-up">
          <div class="post-detail">
            <h2 class="post-title">python-scrapy学习记录</h2>
            <div class="post-date">2020-09-03</div>
            
            <div class="post-content" v-pre>
              <p>scrapy 是 python 的一个爬虫框架，便于快速建立一个爬虫项目。<br>
scrapy 的安装及配置网上教程一大把，在此不做赘述，此文的主要目的是记录所遇到的坑。</p>
<!-- more -->
<p><code>字 数：437,阅读时间:1m 46s</code></p>
<p>1、爬虫速度</p>
<p>​	关于这个，settings.py 内有几个参数可以控制</p>
<ul>
<li>CONCURRENT_REQUESTS_PER_DOMAIN</li>
<li>CONCURRENT_REQUESTS</li>
<li>CONCURRENT_ITEMS</li>
<li>COOKIES_ENABLED</li>
<li>DOWNLOAD_TIMEOUT</li>
</ul>
<p>参数具体描述，请见官方文档。</p>
<p>2、关于分布式爬虫部署</p>
<p>​	scrapy 由于调度中心的数据，在各线程之间是不共享的，因此其本身是不支持分布式部署的。</p>
<p>​	在学习过程中，发现了 scrapy-redis。</p>
<p>​	scrapy-redis修改了 scrapy 的调度中心，将数据存放于 redis 内，多个爬虫从 redis 内去获取数据进行调度，协同处理。</p>
<p>​	1、安装</p>
<p>​	<code>pip install scrapy-redis</code></p>
<p>​	服务器安装 redis，修改配置文件开放允许连接的地址为：0.0.0.0:6379，并且设置一个连接密码，不然相当于在大街上裸奔。</p>
<p>​	设置完毕后，测试下能否连接。</p>
<p>​	2、setting.py配置</p>
<p>​	settins.py 内添加如下内容：</p>
<pre><code>REDIS_HOST = 'host'
REDIS_PORT = 6379
REDIS_ENCODING = 'utf-8'
# REDIS_PARAMS = {'password':'pwd'}
# #使用scrapy-redis组件的去重队列（过滤）
DUPEFILTER_CLASS = &quot;scrapy_redis.dupefilter.RFPDupeFilter&quot;
# #使用scrapy-redis组件自己的调度器(核心代码共享调度器)
SCHEDULER = &quot;scrapy_redis.scheduler.Scheduler&quot;
##是否允许暂停
SCHEDULER_PERSIST = True
ITEM_PIPELINES = {
   'scrapy_redis.pipelines.RedisPipeline': 401,#储存到 redis，如果有自己的，不启用也可
   以
}
</code></pre>
<p>​	3.具体项目的配置</p>
<pre><code class="language-python1">from scrapy_redis.spiders import RedisSpider
class LianghaoGetUrlsSpider(RedisSpider):
    name = 'testName'
	redis_key = “testName:start_urls” #这个是 redis 的 key 名，存储了开始连接
    allowed_domains = ['test.com']

    def parse(self, response):
        pass
</code></pre>
<p>​	4.运行项目</p>
<p>​	进入 redis，</p>
<p>​	<code>rpush testName:start_urls http://www.test.com</code></p>
<p>3、可视化</p>
<p>​	网上教程一把，自己找吧。<br>
​	用到的库：</p>
<pre><code>scrapy
scrapy-redis
pymysql
redis
gerapy
scrapyd
</code></pre>

            </div>
            
              <div class="tag-container">
                
                  <a href="https://quqinyuni.github.io/tag/python/" class="tag">
                    python
                  </a>
                
              </div>
            
            
              <div class="next-post">
                <div class="next">下一篇</div>
                <a href="https://quqinyuni.github.io/post/hello-gridea/">
                  <h3 class="post-title">
                    Hello Gridea
                  </h3>
                </a>
              </div>
            

            

          </div>

        </div>
      </div>
    </div>

    <script src="https://unpkg.com/aos@next/dist/aos.js"></script>
<script type="application/javascript">

AOS.init();

var app = new Vue({
  el: '#app',
  data: {
    menuVisible: false,
  },
})

</script>






  </body>
</html>
